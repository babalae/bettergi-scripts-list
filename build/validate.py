#!/usr/bin/python
# -*- coding: utf-8 -*-
import json
import os
import subprocess
import re
from packaging.version import parse
from semver import VersionInfo

# ==================== é…ç½®å’Œå¸¸é‡ ====================

# å®šä¹‰æœ‰æ•ˆçš„ type å’Œ move_mode å€¼
VALID_TYPES = ["teleport", "path", "target", "orientation"]
VALID_MOVE_MODES = ["swim", "walk", "fly", "climb", "run", "dash", "jump"]

# å®šä¹‰ action å’Œ action_params çš„æœ€ä½å…¼å®¹ç‰ˆæœ¬
ACTION_VERSION_MAP = {
    "fight": "0.42.0",
    "mining": "0.43.0",
    "fishing": "0.43.0",
    "force_tp": "0.42.0",
    "log_output": "0.42.0",
    "anemo_collect": "0.42.0",
    "combat_script": "0.42.0",
    "hydro_collect": "0.42.0",
    "pick_around": "0.42.0",
    "pyro_collect": "0.43.0",
    "stop_flying": "0.42.0",
    "normal_attack": "0.42.0",
    "electro_collect": "0.42.0",
    "nahida_collect": "0.42.0",
    "up_down_grab_leaf": "0.42.0",
    "set_time": "0.45.0"
}

# å®šä¹‰ action_params çš„æœ€ä½å…¼å®¹ç‰ˆæœ¬å’Œæ­£åˆ™è¡¨è¾¾å¼éªŒè¯
ACTION_PARAMS_VERSION_MAP = {
    "stop_flying": {
        "params": {"version": "0.44.0", "regex": r"^\d+(\.\d+)?$"}
    },
    "pick_around": {
        "params": {"version": "0.42.0", "regex": r"^\d+$"}
    },
    "combat_script": {
        "params": {"version": "0.42.0", "regex": r"^.+$"}  # ä»»æ„éç©ºå­—ç¬¦ä¸²
    },
    "log_output": {
        "params": {"version": "0.42.0", "regex": r"^.+$"}  # ä»»æ„éç©ºå­—ç¬¦ä¸²
    }
    # å…¶ä»– action ç±»å‹æ²¡æœ‰æ˜ç¡®çš„ action_params æ ¼å¼è¦æ±‚
}

# é»˜è®¤ç‰ˆæœ¬å·
DEFAULT_BGI_VERSION = "0.42.0"
DEFAULT_VERSION = "1.0"

# ==================== æ–‡ä»¶æ“ä½œ ====================

def get_original_file(file_path):
    """ä»ä¸Šæ¸¸ä»“åº“è·å–åŸå§‹æ–‡ä»¶å†…å®¹ï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯•ä»æœ¬åœ°è·å–"""
    # è¿”å›å€¼å¢åŠ ä¸€ä¸ªæ¥æºæ ‡è¯†: "upstream", "pr_submitted", None

    # é¦–å…ˆå°è¯•ä»ä¸Šæ¸¸ä»“åº“è·å–
    try:
        print(f"å°è¯•ä»upstream/mainè·å–æ–‡ä»¶: {file_path}")
        result = subprocess.run(['git', 'show', f'upstream/main:{file_path}'],
                                capture_output=True, text=True, encoding='utf-8')
        if result.returncode == 0:
            print("ä»ä¸Šæ¸¸ä»“åº“æˆåŠŸè·å–åŸå§‹æ–‡ä»¶")
            return json.loads(result.stdout), "upstream"
        else:
            print(f"æ–‡ä»¶åœ¨ä¸Šæ¸¸ä»“åº“ä¸­ä¸å­˜åœ¨ï¼Œå¯èƒ½æ˜¯æ–°æ–‡ä»¶")
    except Exception as e:
        print(f"ä»ä¸Šæ¸¸ä»“åº“è·å–åŸå§‹æ–‡ä»¶å¤±è´¥: {str(e)}")

    try:
        print("å°è¯•ä½¿ç”¨å½“å‰æ–‡ä»¶ä½œä¸ºPRæäº¤æ–‡ä»¶")
        with open(file_path, 'r', encoding='utf-8') as f:
            current_data = json.load(f)
            # åˆ›å»ºä¸€ä¸ªå‰¯æœ¬ï¼Œé¿å…å¼•ç”¨ç›¸åŒçš„å¯¹è±¡
            return json.loads(json.dumps(current_data)), "pr_submitted"
    except Exception as e:
        print(f"è¯»å–å½“å‰æ–‡ä»¶å¤±è´¥: {str(e)}")

    print("æ— æ³•è·å–ä»»ä½•å½¢å¼çš„åŸå§‹æ–‡ä»¶")
    return None, None

def load_json_file(file_path):
    """åŠ è½½ JSON æ–‡ä»¶"""
    try:
        with open(file_path, encoding='utf-8') as f:
            return json.load(f), None
    except Exception as e:
        return None, f"âŒ JSON æ ¼å¼é”™è¯¯: {str(e)}"

def save_json_file(file_path, data):
    """ä¿å­˜ JSON æ–‡ä»¶"""
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        print(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}")
        return False

# ==================== ç‰ˆæœ¬å¤„ç† ====================

def process_version(current, original, is_new):
    """å¤„ç†ç‰ˆæœ¬å·æ›´æ–°é€»è¾‘"""
    if is_new:
        return DEFAULT_VERSION

    if not original:
        return DEFAULT_VERSION

    try:
        cv = parse(current)
        ov = parse(original)
        # å¼ºåˆ¶æ›´æ–°ç‰ˆæœ¬å·ï¼Œæ— è®ºå½“å‰ç‰ˆæœ¬æ˜¯å¦å¤§äºåŸå§‹ç‰ˆæœ¬
        return f"{ov.major}.{ov.minor + 1}"
    except Exception:
        # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ç®€å•çš„æ•°å­—å¤„ç†
        parts = original.split('.')
        if len(parts) >= 2:
            try:
                major = int(parts[0])
                minor = int(parts[1])
                return f"{major}.{minor + 1}"
            except ValueError:
                pass
        return f"{original}.1"

def extract_required_version(compatibility_issues):
    """ä»å…¼å®¹æ€§é—®é¢˜ä¸­æå–æ‰€éœ€çš„æœ€é«˜ç‰ˆæœ¬å·"""
    required_versions = []
    for issue in compatibility_issues:
        parts = issue.split(">=")
        if len(parts) > 1:
            version_part = parts[1].split(",")[0].strip()
            version_match = re.search(r'(\d+\.\d+\.\d+)', version_part)
            if version_match:
                required_versions.append(version_match.group(1))

    if not required_versions:
        return None

    try:
        return max(required_versions, key=lambda v: VersionInfo.parse(v))
    except ValueError:
        return None

def parse_bgi_version(version_str):
    """è§£æ BGI ç‰ˆæœ¬å·"""
    try:
        # ç¡®ä¿åˆ é™¤ v å‰ç¼€
        return VersionInfo.parse(version_str.lstrip('v'))
    except ValueError:
        return None

# ==================== å­—æ®µéªŒè¯ ====================

def check_action_compatibility(action_type, action_params, bgi_version):
    """æ£€æŸ¥ action å’Œ action_params ä¸ BGI ç‰ˆæœ¬çš„å…¼å®¹æ€§"""
    issues = []
    validation_issues = []

    # å¦‚æœ action_type ä¸ºç©ºï¼Œåˆ™è·³è¿‡æ£€æŸ¥
    if not action_type:
        return issues, validation_issues

    # ç¡®ä¿ bgi_version æ˜¯æœ‰æ•ˆçš„æ ¼å¼
    bgi_ver = parse_bgi_version(bgi_version)
    if not bgi_ver:
        validation_issues.append(f"æ— æ•ˆçš„ bgi_version æ ¼å¼: {bgi_version}")
        return issues, validation_issues

    # æ£€æŸ¥ action å…¼å®¹æ€§
    if action_type in ACTION_VERSION_MAP:
        min_version = ACTION_VERSION_MAP[action_type]
        try:
            if bgi_ver < VersionInfo.parse(min_version):
                issues.append(f"action '{action_type}' éœ€è¦ BGI ç‰ˆæœ¬ >= {min_version}ï¼Œå½“å‰ä¸º {bgi_version}")
        except ValueError:
            validation_issues.append(f"æ— æ³•æ¯”è¾ƒç‰ˆæœ¬: {min_version} ä¸ {bgi_version}")
    else:
        validation_issues.append(f"æœªçŸ¥çš„ action ç±»å‹: '{action_type}'ï¼Œå·²çŸ¥ç±»å‹: {', '.join(sorted(ACTION_VERSION_MAP.keys()))}")

    # æ£€æŸ¥ action_params å…¼å®¹æ€§å’Œæ ¼å¼
    if action_type in ACTION_PARAMS_VERSION_MAP and action_params:
        param_info = ACTION_PARAMS_VERSION_MAP[action_type]["params"]
        min_version = param_info["version"]
        regex_pattern = param_info["regex"]

        # ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥
        try:
            if bgi_ver < VersionInfo.parse(min_version):
                issues.append(f"action '{action_type}' çš„å‚æ•°éœ€è¦ BGI ç‰ˆæœ¬ >= {min_version}ï¼Œå½“å‰ä¸º {bgi_version}")
        except ValueError:
            validation_issues.append(f"æ— æ³•æ¯”è¾ƒç‰ˆæœ¬: {min_version} ä¸ {bgi_version}")

        # å‚æ•°æ ¼å¼éªŒè¯
        if not re.match(regex_pattern, str(action_params)):
            validation_issues.append(f"action '{action_type}' çš„å‚æ•°æ ¼å¼ä¸æ­£ç¡®: '{action_params}'ï¼Œåº”åŒ¹é…æ¨¡å¼: {regex_pattern}")

    return issues, validation_issues

def process_coordinates(positions):
    """ç»Ÿä¸€å¤„ç†åæ ‡ä¿ç•™ä¸¤ä½å°æ•°é€»è¾‘"""
    coord_changed = False
    for pos in positions:
        for axis in ['x', 'y']:
            if axis in pos and isinstance(pos[axis], (int, float)):
                original = pos[axis]
                pos[axis] = round(float(pos[axis]), 2)
                if original != pos[axis]:
                    coord_changed = True
    return coord_changed

def ensure_required_fields(info, filename):
    """ç»Ÿä¸€å¤„ç†å¿…è¦å­—æ®µæ£€æŸ¥é€»è¾‘"""
    corrections = []

    if info["name"] != filename:
        info["name"] = filename
        corrections.append(f"name è‡ªåŠ¨ä¿®æ­£ä¸º {filename}")

    if info["type"] not in ["collect", "fight"]:
        info["type"] = "collect"
        corrections.append("type è‡ªåŠ¨ä¿®æ­£ä¸º collect")

    if not info["author"]:
        info["author"] = os.getenv("GITHUB_ACTOR", "æœªçŸ¥ä½œè€…")
        corrections.append(f"author è‡ªåŠ¨è®¾ç½®ä¸º {info['author']}")

    return corrections

def check_position_fields(positions):
    """æ£€æŸ¥ä½ç½®å­—æ®µçš„æœ‰æ•ˆæ€§

    è‡ªåŠ¨ä¿®å¤åŠŸèƒ½:
    1. ç¼ºå°‘ type å­—æ®µæ—¶ï¼Œè‡ªåŠ¨è®¾ç½®ä¸º 'path'
    2. type å­—æ®µæ— æ•ˆæ—¶ï¼Œè‡ªåŠ¨ä¿®æ­£ä¸º 'path'
    3. å½“ type ä¸º 'path' æˆ– 'target' ä¸”ç¼ºå°‘ move_mode æ—¶ï¼Œè‡ªåŠ¨è®¾ç½®ä¸º 'walk'
    4. move_mode å­—æ®µæ— æ•ˆæ—¶ï¼Œè‡ªåŠ¨ä¿®æ­£ä¸º 'walk'
    """
    validation_issues = []
    notices = []
    corrections = []  # æ·»åŠ ä¿®æ­£åˆ—è¡¨

    for idx, pos in enumerate(positions):
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        required_fields = ["x", "y", "type"]
        missing_fields = [field for field in required_fields if field not in pos]

        if missing_fields:
            validation_issues.append(f"ä½ç½® {idx+1} ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}")
            # è‡ªåŠ¨æ·»åŠ ç¼ºå¤±çš„ type å­—æ®µ
            if "type" in missing_fields:
                pos["type"] = "path"  # è‡ªåŠ¨ä¿®å¤ï¼šç¼ºå°‘ type å­—æ®µæ—¶è®¾ç½®ä¸º path
                corrections.append(f"ä½ç½® {idx+1} ç¼ºå°‘ type å­—æ®µï¼Œå·²è®¾ç½®ä¸ºé»˜è®¤å€¼ 'path'")
                # å¦‚æœæ·»åŠ äº† path ç±»å‹ï¼Œä¹Ÿéœ€è¦æ·»åŠ  move_mode
                if "move_mode" not in pos:
                    pos["move_mode"] = "walk"  # è‡ªåŠ¨ä¿®å¤ï¼šä¸º path ç±»å‹æ·»åŠ é»˜è®¤ move_mode
                    corrections.append(f"ä½ç½® {idx+1} ç¼ºå°‘ move_mode å­—æ®µï¼Œå·²è®¾ç½®ä¸ºé»˜è®¤å€¼ 'walk'")
            # ç§»é™¤ continueï¼Œç¡®ä¿åç»­æ£€æŸ¥èƒ½å¤Ÿæ‰§è¡Œ
            # continue

        # éªŒè¯ type å­—æ®µ
        if "type" in pos:
            pos_type = pos["type"]
            if pos_type not in VALID_TYPES:
                validation_issues.append(f"ä½ç½® {idx+1}: type '{pos_type}' æ— æ•ˆï¼Œæœ‰æ•ˆå€¼ä¸º: {', '.join(VALID_TYPES)}")
                # è‡ªåŠ¨ä¿®æ­£æ— æ•ˆçš„ type å­—æ®µ
                pos["type"] = "path"  # è‡ªåŠ¨ä¿®å¤ï¼šæ— æ•ˆ type ä¿®æ­£ä¸º path
                corrections.append(f"ä½ç½® {idx+1} çš„ type '{pos_type}' æ— æ•ˆï¼Œå·²ä¿®æ­£ä¸º 'path'")
                pos_type = "path"  # æ›´æ–° pos_type ä»¥ä¾¿åç»­æ£€æŸ¥

            # å½“ type ä¸º path æˆ– target æ—¶ï¼ŒéªŒè¯ move_mode
            if pos_type in ["path", "target"]:
                if "move_mode" not in pos:
                    validation_issues.append(f"ä½ç½® {idx+1}: type ä¸º '{pos_type}' æ—¶å¿…é¡»æŒ‡å®š move_mode")
                    # è‡ªåŠ¨æ·»åŠ ç¼ºå¤±çš„ move_mode
                    pos["move_mode"] = "walk"  # è‡ªåŠ¨ä¿®å¤ï¼šç¼ºå°‘ move_mode æ—¶è®¾ç½®ä¸º walk
                    corrections.append(f"ä½ç½® {idx+1} ç¼ºå°‘ move_mode å­—æ®µï¼Œå·²è®¾ç½®ä¸ºé»˜è®¤å€¼ 'walk'")
                elif pos["move_mode"] not in VALID_MOVE_MODES:
                    validation_issues.append(f"ä½ç½® {idx+1}: move_mode '{pos['move_mode']}' æ— æ•ˆï¼Œæœ‰æ•ˆå€¼ä¸º: {', '.join(VALID_MOVE_MODES)}")
                    # è‡ªåŠ¨ä¿®æ­£æ— æ•ˆçš„ move_mode
                    pos["move_mode"] = "walk"  # è‡ªåŠ¨ä¿®å¤ï¼šæ— æ•ˆ move_mode ä¿®æ­£ä¸º walk
                    corrections.append(f"ä½ç½® {idx+1} çš„ move_mode '{pos['move_mode']}' æ— æ•ˆï¼Œå·²ä¿®æ­£ä¸º 'walk'")

        # æ£€æŸ¥ç¬¬ä¸€ä¸ªä½ç½®æ˜¯å¦ä¸º teleport
        if idx == 0 and pos.get("type") != "teleport":
            notices.append("âš ï¸ ç¬¬ä¸€ä¸ª position çš„ type ä¸æ˜¯ teleport")

    return validation_issues, notices, corrections

def check_bgi_version_compatibility(bgi_version, auto_fix=False):
    """æ£€æŸ¥ BGI ç‰ˆæœ¬å…¼å®¹æ€§"""
    corrections = []

    # åˆ é™¤å¯èƒ½å­˜åœ¨çš„ v å‰ç¼€
    if bgi_version.startswith('v'):
        bgi_version = bgi_version.lstrip('v')
        corrections.append(f"bgi_version å‰ç¼€ 'v' å·²åˆ é™¤")

    bgi_ver = parse_bgi_version(bgi_version)

    if not bgi_ver:
        if auto_fix:
            corrections.append(f"bgi_version {bgi_version} æ ¼å¼æ— æ•ˆï¼Œè‡ªåŠ¨æ›´æ–°ä¸º {DEFAULT_BGI_VERSION}")
            return DEFAULT_BGI_VERSION, corrections
        return bgi_version, []

    if bgi_ver < VersionInfo.parse(DEFAULT_BGI_VERSION):
        if auto_fix:
            corrections.append(f"bgi_version {bgi_version} è‡ªåŠ¨æ›´æ–°ä¸º {DEFAULT_BGI_VERSION} (åŸç‰ˆæœ¬ä½äºè¦æ±‚)")
            return DEFAULT_BGI_VERSION, corrections

    return bgi_version, corrections

# ==================== ä¸»éªŒè¯é€»è¾‘ ====================

def initialize_data(data, file_path):
    """åˆå§‹åŒ–æ•°æ®ç»“æ„ï¼Œç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨"""
    messages = []

    if "info" not in data:
        data["info"] = {}
        messages.append(f"âš ï¸ æ–‡ä»¶ç¼ºå°‘ info å­—æ®µï¼Œå·²æ·»åŠ é»˜è®¤å€¼")

    info = data["info"]
    filename = os.path.splitext(os.path.basename(file_path))[0]

    # æ£€æŸ¥å¹¶æ·»åŠ å¿…è¦çš„å­—æ®µ
    if "name" not in info:
        info["name"] = filename
        messages.append(f"âš ï¸ æ–‡ä»¶ç¼ºå°‘ name å­—æ®µï¼Œå·²è®¾ç½®ä¸ºæ–‡ä»¶å: {info['name']}")

    if "type" not in info:
        info["type"] = "collect"
        messages.append(f"âš ï¸ æ–‡ä»¶ç¼ºå°‘ type å­—æ®µï¼Œå·²è®¾ç½®ä¸ºé»˜è®¤å€¼: collect")

    if "author" not in info:
        info["author"] = os.getenv("GITHUB_ACTOR", "æœªçŸ¥ä½œè€…")
        messages.append(f"âš ï¸ æ–‡ä»¶ç¼ºå°‘ author å­—æ®µï¼Œå·²è®¾ç½®ä¸º: {info['author']}")

    if "version" not in info:
        info["version"] = DEFAULT_VERSION
        messages.append(f"âš ï¸ æ–‡ä»¶ç¼ºå°‘ version å­—æ®µï¼Œå·²è®¾ç½®ä¸ºé»˜è®¤å€¼: {DEFAULT_VERSION}")

    if "bgi_version" not in info:
        info["bgi_version"] = DEFAULT_BGI_VERSION
        messages.append(f"âš ï¸ æ–‡ä»¶ç¼ºå°‘ bgi_version å­—æ®µï¼Œå·²è®¾ç½®ä¸ºé»˜è®¤å€¼: {DEFAULT_BGI_VERSION}")

    if "positions" not in data:
        data["positions"] = []
        messages.append(f"âš ï¸ æ–‡ä»¶ç¼ºå°‘ positions å­—æ®µï¼Œå·²æ·»åŠ ç©ºæ•°ç»„")

    for message in messages:
        print(message)

    return data

def check_actions_compatibility(positions, bgi_version):
    """æ£€æŸ¥æ‰€æœ‰ä½ç½®çš„ action å…¼å®¹æ€§"""
    compatibility_issues = []
    validation_issues = []

    for idx, pos in enumerate(positions):
        action_type = pos.get("action", "")
        action_params = pos.get("params", "")

        if action_type:
            compat_issues, valid_issues = check_action_compatibility(action_type, action_params, bgi_version)

            for issue in compat_issues:
                compatibility_issues.append(f"ä½ç½® {idx+1}: {issue}")

            for issue in valid_issues:
                validation_issues.append(f"ä½ç½® {idx+1}: {issue}")

    return compatibility_issues, validation_issues

def update_bgi_version_for_compatibility(info, compatibility_issues, auto_fix):
    """æ ¹æ®å…¼å®¹æ€§é—®é¢˜æ›´æ–° BGI ç‰ˆæœ¬"""
    corrections = []

    if auto_fix and compatibility_issues:
        max_required = extract_required_version(compatibility_issues)

        if max_required:
            # ç¡®ä¿ max_required æ²¡æœ‰ v å‰ç¼€
            max_required = max_required.lstrip('v')

            try:
                current_bgi = parse_bgi_version(info["bgi_version"])
                if current_bgi and current_bgi < VersionInfo.parse(max_required):
                    info["bgi_version"] = max_required
                    corrections.append(f"bgi_version {info['bgi_version']} è‡ªåŠ¨æ›´æ–°ä¸º {max_required} ä»¥å…¼å®¹æ‰€æœ‰åŠŸèƒ½")
                    return [], corrections
            except ValueError as e:
                print(f"è­¦å‘Š: ç‰ˆæœ¬å·è§£æå¤±è´¥ - {e}")
                info["bgi_version"] = DEFAULT_BGI_VERSION
                corrections.append(f"bgi_version è‡ªåŠ¨æ›´æ–°ä¸º {DEFAULT_BGI_VERSION} (ç‰ˆæœ¬è§£æå¤±è´¥)")
                return [], corrections

    return compatibility_issues, corrections

def validate_file(file_path, auto_fix=False):
    """éªŒè¯å¹¶ä¿®å¤ JSON æ–‡ä»¶"""
    # åŠ è½½æ–‡ä»¶
    data, error = load_json_file(file_path)
    if error:
        print(error)
        return []

    # è·å–åŸå§‹æ–‡ä»¶
    original_data, source = get_original_file(file_path) if auto_fix else (None, None)
    is_new = not original_data if auto_fix else True

    # åˆå§‹åŒ–æ•°æ®ç»“æ„
    data = initialize_data(data, file_path)
    info = data["info"]
    filename = os.path.splitext(os.path.basename(file_path))[0]

    # æ”¶é›†æ‰€æœ‰ä¿®æ­£ - ä¿®å¤ï¼šæ·»åŠ äº†è¿™ä¸€è¡Œæ¥å®šä¹‰ all_corrections å˜é‡
    all_corrections = []

    # æ£€æŸ¥å¿…è¦å­—æ®µ
    corrections = ensure_required_fields(info, filename)
    all_corrections.extend(corrections)

    # å¤„ç†åæ ‡
    coord_changed = process_coordinates(data["positions"])
    if coord_changed:
        all_corrections.append("åæ ‡å€¼è‡ªåŠ¨ä¿ç•™ä¸¤ä½å°æ•°")

    # æ£€æŸ¥ BGI ç‰ˆæœ¬å…¼å®¹æ€§
    bgi_version, corrections = check_bgi_version_compatibility(info["bgi_version"], auto_fix)
    if corrections:
        info["bgi_version"] = bgi_version
        all_corrections.extend(corrections)

    # æ£€æŸ¥ä½ç½®å­—æ®µ - ä¿®æ”¹ä¸ºæ¥æ”¶ä¸‰ä¸ªè¿”å›å€¼
    position_issues, notices, pos_corrections = check_position_fields(data["positions"])
    if auto_fix and pos_corrections:
        all_corrections.extend(pos_corrections)

    # æ£€æŸ¥ action å…¼å®¹æ€§
    compatibility_issues, action_validation_issues = check_actions_compatibility(data["positions"], info["bgi_version"])
    position_issues.extend(action_validation_issues)

    # æ ¹æ®å…¼å®¹æ€§é—®é¢˜æ›´æ–° BGI ç‰ˆæœ¬
    compatibility_issues, corrections = update_bgi_version_for_compatibility(info, compatibility_issues, auto_fix)
    all_corrections.extend(corrections)

    # æ›´æ–°ç‰ˆæœ¬å· - åªæœ‰ä»ä¸Šæ¸¸ä»“åº“è·å–çš„æ–‡ä»¶æ‰æ›´æ–°ç‰ˆæœ¬å·
    # if auto_fix:
    if False:
        has_original_version = False
        original_version = None

        if original_data and "info" in original_data and "version" in original_data["info"]:
            original_version = original_data["info"]["version"]
            has_original_version = True
            print(f"æˆåŠŸè·å–åŸå§‹ç‰ˆæœ¬å·: {original_version}")
        else:
            print("æœªæ‰¾åˆ°åŸå§‹ç‰ˆæœ¬å·ï¼Œå°†è§†ä¸ºæ–°æ–‡ä»¶å¤„ç†")

        # åªæœ‰åœ¨æ²¡æœ‰åŸå§‹ç‰ˆæœ¬å·æ—¶æ‰è§†ä¸ºæ–°æ–‡ä»¶
        is_new = not has_original_version

        print(f"åŸå§‹ç‰ˆæœ¬å·: {original_version}, å½“å‰ç‰ˆæœ¬å·: {info['version']}, æ˜¯å¦æ–°æ–‡ä»¶: {is_new}, æ¥æº: {source}")

        # åªæœ‰å½“æ–‡ä»¶æ¥æºæ˜¯ä¸Šæ¸¸ä»“åº“æ—¶æ‰æ›´æ–°ç‰ˆæœ¬å·
        if source == "upstream":
            new_version = process_version(info["version"], original_version, is_new)
            if new_version != info["version"]:
                info["version"] = new_version
                all_corrections.append(f"version è‡ªåŠ¨æ›´æ–°ä¸º {new_version}")
                print(f"ç‰ˆæœ¬å·å·²æ›´æ–°: {info['version']}")
            else:
                print(f"ç‰ˆæœ¬å·æœªå˜åŒ–: {info['version']}")
        else:
            print(f"è¿™æ˜¯PRæäº¤çš„æ–‡ä»¶ï¼Œä¿æŒç‰ˆæœ¬å·ä¸å˜: {info['version']}ï¼ˆåˆå¹¶åå†æ›´æ–°ç‰ˆæœ¬ï¼‰")

    # åˆå¹¶æ‰€æœ‰é€šçŸ¥
    for issue in compatibility_issues:
        notices.append(issue)

    for issue in position_issues:
        notices.append(issue)

    # ä¿å­˜ä¿®æ­£
    if auto_fix:
        # æ— è®ºæ˜¯å¦æœ‰é—®é¢˜ï¼Œéƒ½æ‰“å°æ‰€æœ‰è‡ªåŠ¨ä¿®æ­£é¡¹
        if all_corrections:
            print("ğŸ”§ è‡ªåŠ¨ä¿®æ­£:")
            for correction in all_corrections:
                print(f"  - {correction}")
        else:
            print("âœ… æ²¡æœ‰éœ€è¦è‡ªåŠ¨ä¿®æ­£çš„é¡¹ç›®")

        # åªæœ‰åœ¨æœ‰ä¿®æ­£æˆ–é—®é¢˜æ—¶æ‰ä¿å­˜æ–‡ä»¶
        if all_corrections or position_issues:
            if save_json_file(file_path, data):
                print("âœ… æ–‡ä»¶å·²ä¿å­˜")
            else:
                notices.append("âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥")

    return notices

def main():
    import argparse

    parser = argparse.ArgumentParser(description='æ ¡éªŒ BetterGI è„šæœ¬æ–‡ä»¶')
    parser.add_argument('path', help='è¦æ ¡éªŒçš„æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--fix', action='store_true', help='è‡ªåŠ¨ä¿®å¤é—®é¢˜')
    args = parser.parse_args()

    path = args.path
    auto_fix = args.fix
    all_notices = []  # åˆå§‹åŒ– all_notices å˜é‡

    if os.path.isfile(path) and path.endswith('.json'):
        print(f"\nğŸ” æ ¡éªŒæ–‡ä»¶: {path}")
        notices = validate_file(path, auto_fix)
        if notices:
            all_notices.extend([f"{path}: {n}" for n in notices])  # æ·»åŠ åˆ° all_notices
            print("\næ ¡éªŒæ³¨æ„äº‹é¡¹:")
            for notice in notices:
                print(f"- {notice}")
        else:
            print("âœ… æ ¡éªŒå®Œæˆï¼Œæ²¡æœ‰å‘ç°é—®é¢˜")
    elif os.path.isdir(path):
        for root, _, files in os.walk(path):
            for file in files:
                if file.endswith('.json'):
                    file_path = os.path.join(root, file)
                    print(f"\nğŸ” æ ¡éªŒæ–‡ä»¶: {file_path}")
                    notices = validate_file(file_path, auto_fix)
                    if notices:
                        all_notices.extend([f"{file_path}: {n}" for n in notices])

        if all_notices:
            print("\næ‰€æœ‰æ ¡éªŒæ³¨æ„äº‹é¡¹:")
            for notice in all_notices:
                print(f"- {notice}")
        else:
            print("\nâœ… æ‰€æœ‰æ–‡ä»¶æ ¡éªŒå®Œæˆï¼Œæ²¡æœ‰å‘ç°é—®é¢˜")
    else:
        print(f"âŒ æ— æ•ˆçš„è·¯å¾„: {path}")

    # ç”Ÿæˆæé†’ä¿¡æ¯
    if all_notices:
        with open('validation_notes.md', 'w') as f:
            f.write("## æ ¡éªŒæ³¨æ„äº‹é¡¹\n\n" + "\n".join(f"- {n}" for n in all_notices))

if __name__ == "__main__":
    main()
